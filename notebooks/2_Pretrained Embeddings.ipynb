{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requirements for this notebook:\n",
    "1. Internet connection (to download corpora and tokenizer data with calls to nltk.download())\n",
    "3. Download this file and keep track of the path where it goes:\n",
    "  1. https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit?usp=sharing\n",
    "2. The following packages:\n",
    "  1. nltk (Anaconda or PIP command line install : pip install -U nltk OR conda install nltk)\n",
    "  2. gensim (pip install -U gensim)\n",
    "  3. scikit-learn v0.18.1 (pip install -U scikit-learn)\n",
    "  4. matplotlib (pip install -U matplotlib)\n",
    "  5. numpy (pip install -U numpy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objectives of this notebook are to illustrate how we can load and explore pre-trained word embeddings\n",
    "1. Loading pre-trained embeddings with GenSim\n",
    "2. Explore embeddings vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gensim page : https://radimrehurek.com/gensim/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.configdefaults): g++ not detected ! Theano will be unable to execute optimized C-implementations (for both CPU and GPU) and will default to Python implementations. Performance will be severely degraded. To remove this warning, set Theano flags cxx to an empty string.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'0.12.4'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gensim\n",
    "gensim.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit-learn page : http://scikit-learn.org/stable/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.17.1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn.manifold import TSNE\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.10.4'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.models import Doc2Vec\n",
    "from gensim.models.doc2vec import LabeledSentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Before we begin, let's talk about some sources of pre-trained embeddings:\n",
    "1.  Non-clinical Word2Vec\n",
    "  1. GoogleNews (download : https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit?usp=sharing more info : https://code.google.com/archive/p/word2vec/)\n",
    "2. Clinical Word Vectors\n",
    "  1. PubMed and PubMed Wikipedia from http://bio.nlplab.org/ (download : http://evexdb.org/pmresources/vec-space-models/)\n",
    "  2. BioASQ trained PubMed embeddings (http://bioasq.org/news/bioasq-releases-continuous-space-word-vectors-obtained-applying-word2vec-pubmed-abstracts) \n",
    "3. Clincal Data (Codes, Events)\n",
    "  1. http://clinicalml.org/ (from this paper : https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5001761/)\n",
    "4. GloVe embeddings (similar to word2vec but uses global words statistics)\n",
    "  1. While these are not compatible with GenSim out-of-the-box, there are scripts to make this work : (https://radimrehurek.com/gensim/scripts/glove2word2vec.html)\n",
    "  2. Download and more info : http://nlp.stanford.edu/projects/glove/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's load our pre-trained embeddings from Google:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "GOOGLE_EMBEDDINGS_PATH = 'C:/temp-embeddings/GoogleNews-vectors-negative300.bin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Loading Google News model from : ' + GOOGLE_EMBEDDINGS_PATH)\n",
    "\n",
    "google_w2v_model = Word2Vec.load_word2vec_format(GOOGLE_EMBEDDINGS_PATH, binary=True)  # C binary format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('GoogleNews Model vocab size : ', 3000000)\n"
     ]
    }
   ],
   "source": [
    "print('GoogleNews Model vocab size : ', len(google_w2v_model.vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's also load our NLTK resources so that we can try to re-classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\u0061995\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "Wall time: 1.95 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time nltk.download('brown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     C:\\Users\\u0061995\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n",
      "Wall time: 754 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time nltk.download('movie_reviews')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import brown\n",
    "from nltk.corpus import movie_reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's start inspect our pre-trained vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now let's inspect what some of these vectors look like\n",
    "#print(google_w2v_model['business'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.867676976388\n"
     ]
    }
   ],
   "source": [
    "# Now let's see how similar certain word pairs might be\n",
    "TERM_SIMILARITY_1 = 'movie'\n",
    "TERM_SIMILARITY_2 = 'film'\n",
    "\n",
    "print(google_w2v_model.similarity(TERM_SIMILARITY_1, TERM_SIMILARITY_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.162694340463\n"
     ]
    }
   ],
   "source": [
    "# Now let's try another pair\n",
    "TERM_SIMILARITY_3 = 'computer'\n",
    "TERM_SIMILARITY_4 = 'life'\n",
    "\n",
    "print(google_w2v_model.similarity(TERM_SIMILARITY_3, TERM_SIMILARITY_4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Can we replicate the famous example from this paper:\n",
    "# \"King - Man + Woman ~~ Queen\"\n",
    "# http://www.aclweb.org/anthology/N13-1#page=784\n",
    "RELATIONSHIP_WORD_1 = 'woman'\n",
    "RELATIONSHIP_WORD_2 = 'king'\n",
    "RELATIONSHIP_WORD_3 = 'man'\n",
    "\n",
    "# this gives what we might expect from the MOVIE corpus\n",
    "#RELATIONSHIP_WORD_1 = 'films'\n",
    "#RELATIONSHIP_WORD_2 = 'movie'\n",
    "#RELATIONSHIP_WORD_3 = 'film'\n",
    "\n",
    "# this gives what we might expect from the BROWN corpus\n",
    "#RELATIONSHIP_WORD_1 = 'families'\n",
    "#RELATIONSHIP_WORD_2 = 'city'\n",
    "#RELATIONSHIP_WORD_3 = 'family'\n",
    "\n",
    "# This can take a very long time (minutes) with GoogleNews model\n",
    "#print(google_w2v_model.most_similar(positive=[RELATIONSHIP_WORD_1, RELATIONSHIP_WORD_2], negative=[RELATIONSHIP_WORD_3]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
